---
title: "Decision Trees Quarto - Enhanced Analysis"
format:
  html:
    toc: true
    toc-depth: 4
    html-math-method: katex
    fontsize: 11pt
    fig-width: 8
    fig-height: 6
    df-print: paged
    code-overflow: wrap
    self-contained: true
editor: visual
---

# Data Preparation

```{r setup}
#| label: setup
#| warning: false
#| message: false 

# Load required libraries
library(tidyverse)
library(caTools)
library(rpart)
library(rpart.plot)
library(caret)
library(Boruta)
library(cvms)
library(dplyr)
library(caret)
library(kableExtra)
library(gridExtra)
```

```{r data-loading}
#| label: data-loading
#| warning: false
#| message: false 

# Load training data
flight_data_train <- read_csv("~/FlightProject/flight_data_train.csv") %>%
  as.data.frame() %>%
  select(-data_set_division)

# Load test data  
flight_data_test <- read_csv("~/FlightProject/flight_data_test.csv") %>%
  as.data.frame()%>%
  select(-data_set_division)

# Display training data structure
glimpse(flight_data_train)
```

Replacing the missing values for airport stops with NONE.

```{r data-cleaning}
#| label: data-cleaning
#| warning: false
#| message: false 

flight_data_train <- flight_data_train %>%
  mutate(
    # Replace missing airport stops with "NONE" 
    airport_code_first_stop = ifelse(is.na(airport_code_first_stop), "NONE", airport_code_first_stop),
    airport_code_second_stop = ifelse(is.na(airport_code_second_stop), "NONE", airport_code_second_stop),
    airport_code_third_stop = ifelse(is.na(airport_code_third_stop), "NONE", airport_code_third_stop)
  )

flight_data_test <- flight_data_test %>%
  mutate(
    # Replace missing airport stops with "NONE" 
    airport_code_first_stop = ifelse(is.na(airport_code_first_stop), "NONE", airport_code_first_stop),
    airport_code_second_stop = ifelse(is.na(airport_code_second_stop), "NONE", airport_code_second_stop),
    airport_code_third_stop = ifelse(is.na(airport_code_third_stop), "NONE", airport_code_third_stop)
  )
```

## Feature Engineering

```{r feature-engineering}
#| label: feature-engineering
#| warning: false
#| message: false 

# Create engineered features for training data
flight_data_train_processed <- flight_data_train %>%
  mutate(
    # Convert categorical stops to numeric feature
    number_of_stops = case_when(
      Total_Stops == "non-stop" ~ 0,
      Total_Stops == "1 stop" ~ 1,
      Total_Stops == "2 stops" ~ 2,
      Total_Stops == "3 stops" ~ 3,
      Total_Stops == "4 stops" ~ 4
    ),
    # Create weekend indicator feature
    weekend = case_when(
      departure_day_of_week %in% c("Sunday", "Saturday") ~ "Weekend",
      TRUE ~ "Weekday"
    )
  )

# Apply same transformations to test data
flight_data_test_processed <- flight_data_test %>%
  mutate(
    number_of_stops = case_when(
      Total_Stops == "non-stop" ~ 0,
      Total_Stops == "1 stop" ~ 1,
      Total_Stops == "2 stops" ~ 2,
      Total_Stops == "3 stops" ~ 3,
      Total_Stops == "4 stops" ~ 4
    ),
    weekend = case_when(
      departure_day_of_week %in% c("Sunday", "Saturday") ~ "Weekend",
      TRUE ~ "Weekday"
    )
  )
```

```{r}
#| warning: false
#| message: false 
#| echo: false
cat("Training samples:", nrow(flight_data_train_processed), "\n")
cat("Test samples:", nrow(flight_data_test_processed), "\n")
```

# Model Development

## Baseline and Deep Decision Tree Models

```{r model-fitting, message=FALSE, warning=FALSE}
set.seed(42)

# Define core features for models
baseline_features <- c("Departure_Day", "Departure_Month", "Departure_Hour", 
                      "Duration_Hours", "number_of_stops", "weekend",
                      "Airline", "airport_code_arrival", "airport_code_departure",
                      "airport_code_first_stop", "airport_code_second_stop", 
                      "airport_code_third_stop")

# Baseline Decision Tree
model_baseline <- rpart(
  Price ~ Departure_Day + Departure_Month + Departure_Hour + Duration_Hours +
    number_of_stops + weekend + Airline + airport_code_arrival +
    airport_code_departure + airport_code_first_stop +
    airport_code_second_stop + airport_code_third_stop,
  data = flight_data_train_processed, 
  method = "anova"
)

# Enhanced Decision Tree (with temporal features)
model_enhanced <- rpart(
  Price ~ Departure_Day + Departure_Month + Departure_Hour + Duration_Hours +
    number_of_stops + weekend + Date_of_Journey + departure_date_time +
    arrival_date_time + Airline + airport_code_arrival +
    airport_code_departure + airport_code_first_stop +
    airport_code_second_stop + airport_code_third_stop,
  data = flight_data_train_processed, 
  method = "anova"
)

# Deep Decision Tree (optimal complexity)
model_deep <- rpart(
  Price ~ Departure_Day + Departure_Month + Departure_Hour + Duration_Hours +
    number_of_stops + weekend + Date_of_Journey + departure_date_time +
    arrival_date_time + Airline + airport_code_arrival +
    airport_code_departure + airport_code_first_stop +
    airport_code_second_stop + airport_code_third_stop,
  data = flight_data_train_processed, 
  method = "anova",
  minsplit = 8, minbucket = 2, maxdepth = 30
)

# Overfitted Decision Tree (for comparison)
model_overfit <- rpart(
  Price ~ Departure_Day + Departure_Month + Departure_Hour + Duration_Hours +
    number_of_stops + weekend + Date_of_Journey + departure_date_time +
    arrival_date_time + Airline + airport_code_arrival +
    airport_code_departure + airport_code_first_stop +
    airport_code_second_stop + airport_code_third_stop,
  data = flight_data_train_processed, 
  method = "anova",
  minsplit = 8, minbucket = 2, maxdepth = 30, cp = -1
)
```

**Key Model Differences:**

-   **Baseline**: Core features only (airline, route, timing basics)

-   **Enhanced**: Adds specific date/time features for dynamic pricing

-   **Deep**: Optimal complexity with controlled overfitting prevention

-   **Overfitted**: No complexity penalty (cp = -1) for comparison

```{r baseline-visualization, message=FALSE, warning=FALSE, fig.width=12, fig.height=8}
# Visualize the deep model (best performer)
rpart.plot(model_baseline, 
          main = "Baseline Decision Tree for Flight Price Prediction",
          cex = 0.6, tweak = 1.2, box.palette = "Blues",
          shadow.col = "gray", split.cex = 0.8, nn.cex = 0.7)
```

```{r deep model-visualization, message=FALSE, warning=FALSE, fig.width=12, fig.height=8}
# Visualize the deep model (best performer)
rpart.plot(model_deep, 
          main = "Deep Decision Tree for Flight Price Prediction",
          cex = 0.6, tweak = 1.2, box.palette = "Blues",
          shadow.col = "gray", split.cex = 0.8, nn.cex = 0.7)
```

The deep model uses 10 splits and reveals that route structure (first stop) and temporal factors drive the primary pricing decisions, followed by airline brand and duration considerations.

## Stratified Cross-Validation Analysis

```{r stratified-cv,  message=FALSE, warning=FALSE}
# Create price bins for stratification
flight_data_train_processed$price_bin <- cut(flight_data_train_processed$Price, 
                                           breaks = quantile(flight_data_train_processed$Price, 
                                                           probs = c(0, 0.25, 0.5, 0.75, 1.0)),
                                           labels = c("Low", "Medium", "High", "Very_High"),
                                           include.lowest = TRUE)

# Pre-process factor levels to ensure consistency
factor_cols <- c("Airline", "airport_code_arrival", "airport_code_departure", 
                 "airport_code_first_stop", "airport_code_second_stop", 
                 "airport_code_third_stop", "weekend")

for(col in factor_cols) {
  flight_data_train_processed[[col]] <- factor(flight_data_train_processed[[col]])
}

# Create stratified folds
set.seed(42)
stratified_folds <- createFolds(flight_data_train_processed$price_bin, 
                               k = 10, list = TRUE, returnTrain = FALSE)

# Stratified CV function
stratified_cv_rpart <- function(data, folds, model_name) {
  cv_results <- data.frame(fold = integer(), rmse = numeric(), 
                          r_squared = numeric(), mae = numeric())
  
  for(i in 1:length(folds)) {
    test_indices <- folds[[i]]
    train_data <- data[-test_indices, ]
    test_data <- data[test_indices, ]
    
    # Ensure consistent factor levels
    for(col in factor_cols) {
      train_data[[col]] <- factor(train_data[[col]], levels = levels(data[[col]]))
      test_data[[col]] <- factor(test_data[[col]], levels = levels(data[[col]]))
    }
    
    # Fit appropriate model
    if(model_name == "deep") {
      model <- rpart(Price ~ Departure_Day + Departure_Month + Departure_Hour + Duration_Hours +
                     number_of_stops + weekend + Date_of_Journey + departure_date_time +
                     arrival_date_time + Airline + airport_code_arrival +
                     airport_code_departure + airport_code_first_stop +
                     airport_code_second_stop + airport_code_third_stop,
                     data = train_data, method = "anova",
                     minsplit = 8, minbucket = 2, maxdepth = 30)
    } else if(model_name == "overfitted") {
      model <- rpart(Price ~ Departure_Day + Departure_Month + Departure_Hour + Duration_Hours +
                     number_of_stops + weekend + Date_of_Journey + departure_date_time +
                     arrival_date_time + Airline + airport_code_arrival +
                     airport_code_departure + airport_code_first_stop +
                     airport_code_second_stop + airport_code_third_stop,
                     data = train_data, method = "anova",
                     minsplit = 8, minbucket = 2, maxdepth = 30, cp = -1)
    }
    
    predictions <- predict(model, test_data)
    rmse <- sqrt(mean((test_data$Price - predictions)^2))
    r_squared <- cor(test_data$Price, predictions)^2
    mae <- mean(abs(test_data$Price - predictions))
    
    cv_results <- rbind(cv_results, data.frame(
      fold = i, rmse = rmse, r_squared = r_squared, mae = mae))
  }
  
  return(cv_results)
}

# Run stratified CV for both models
deep_cv_results <- stratified_cv_rpart(flight_data_train_processed, stratified_folds, "deep")
overfitted_cv_results <- stratified_cv_rpart(flight_data_train_processed, stratified_folds, "overfitted")
```

```{r cv-results}
# Summary results
stratified_cv_comparison <- data.frame(
  Model = c("Deep (Stratified CV)", "Overfitted (Stratified CV)"),
  Mean_RMSE = c(round(mean(deep_cv_results$rmse), 2), round(mean(overfitted_cv_results$rmse), 2)),
  SD_RMSE = c(round(sd(deep_cv_results$rmse), 2), round(sd(overfitted_cv_results$rmse), 2)),
  Mean_R_squared = c(round(mean(deep_cv_results$r_squared), 3), round(mean(overfitted_cv_results$r_squared), 3)),
  SD_R_squared = c(round(sd(deep_cv_results$r_squared), 3), round(sd(overfitted_cv_results$r_squared), 3)),
  Mean_MAE = c(round(mean(deep_cv_results$mae), 2), round(mean(overfitted_cv_results$mae), 2))
)

stratified_cv_comparison %>%
  kbl(caption = "Stratified Cross-Validation Results",
      col.names = c("Model", "Mean RMSE", "SD RMSE", "Mean R²", "SD R²", "Mean MAE")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE, position = "left")
```

**Stratified CV Key Findings:**

-   **Deep Model**: 72.3% R² (much more realistic than original \~52% CV)
-   **Overfitted Model**: 76.8% R² (only 4.5 percentage points better)
-   **Stability**: Deep model shows lower variance across folds (RMSE SD: 175 vs 229)

The stratified CV reveals that price outlier distribution was skewing original cross-validation results. When properly validated, the overfitted model's advantage shrinks dramatically while requiring 130x more complexity.

# Model Performance Comparison

```{r test-predictions}
# Function to evaluate model performance
evaluate_model <- function(model, test_data, model_name) {
  predictions <- predict(model, test_data)
  rmse <- sqrt(mean((test_data$Price - predictions)^2))
  r_squared <- (cor(test_data$Price, predictions))^2
  correlation <- cor(test_data$Price, predictions)
  
  data.frame(
    Model = model_name,
    RMSE = round(rmse, 2),
    R_squared = round(r_squared, 3),
    Correlation = round(correlation, 3)
  )
}

# Evaluate all models on test data
model_comparison <- bind_rows(
  evaluate_model(model_baseline, flight_data_test_processed, "Baseline"),
  evaluate_model(model_enhanced, flight_data_test_processed, "Enhanced"), 
  evaluate_model(model_deep, flight_data_test_processed, "Deep"),
  evaluate_model(model_overfit, flight_data_test_processed, "Overfitted")
)

model_comparison %>%
  kbl(caption = "Test Set Performance Comparison",
      col.names = c("Model", "RMSE", "R-squared", "Correlation")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE, position = "left")
```

## Side-by-Side Model Performance Visualizations

```{r performance-plots, message=FALSE, warning=FALSE, fig.width=16, fig.height=10}
# Generate predictions for visualization
deep_predictions <- predict(model_deep, flight_data_test_processed)
overfitted_predictions <- predict(model_overfit, flight_data_test_processed)

flight_data_test_processed$deep_predicted <- deep_predictions
flight_data_test_processed$overfitted_predicted <- overfitted_predictions

# Create side-by-side performance plots
p1 <- flight_data_test_processed %>%
  ggplot(aes(x = Price, y = deep_predicted)) +
  geom_point(alpha = 0.6, size = 1.5, position = position_jitter(width = 50)) +
  geom_smooth(method = 'lm', se = TRUE, color = "red") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "blue") +
  labs(title = "Deep Model: Predicted vs Actual",
       subtitle = paste("R² =", round(cor(flight_data_test_processed$Price, deep_predictions)^2, 3),
                       "| RMSE =", round(sqrt(mean((flight_data_test_processed$Price - deep_predictions)^2)), 2)),
       x = "Actual Price (₹)", y = "Predicted Price (₹)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.text = element_text(size = 14))+ 
  guides(fill = guide_legend(reverse=T))

p2 <- flight_data_test_processed %>%
  ggplot(aes(x = Price, y = overfitted_predicted)) +
  geom_point(alpha = 0.6, size = 1.5, position = position_jitter(width = 50)) +
  geom_smooth(method = 'lm', se = TRUE, color = "red") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "blue") +
  labs(title = "Overfitted Model: Predicted vs Actual",
       subtitle = paste("R² =", round(cor(flight_data_test_processed$Price, overfitted_predictions)^2, 3),
                       "| RMSE =", round(sqrt(mean((flight_data_test_processed$Price - overfitted_predictions)^2)), 2)),
       x = "Actual Price (₹)", y = "Predicted Price (₹)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.text = element_text(size = 14)) + 
  guides(fill = guide_legend(reverse=T))

grid.arrange(p1, p2, ncol = 2)
```

**Visual Comparison Insights:**

-   Both models show strong linear relationships with actual prices

-   The overfitted model shows slightly tighter clustering around the diagonal

-   Both exhibit characteristic decision tree "banding" - decrete predictions from leaf nodes

-   Performance difference is less dramatic visually than the complexity difference would suggest

## Combined Airline-Route Pricing Analysis

```{r combined-pricing-analysis, message=FALSE, warning=FALSE, fig.width=14, fig.height=15}
# Generate predictions for training data to analyze pricing patterns
deep_train_predictions <- predict(model_deep, flight_data_train_processed)
overfitted_train_predictions <- predict(model_overfit, flight_data_train_processed)

# Combined pricing analysis
combined_pricing_analysis <- flight_data_train_processed %>%
  mutate(
    deep_predicted = deep_train_predictions,
    overfitted_predicted = overfitted_train_predictions
  ) %>%
  group_by(Airline, airport_code_arrival) %>%
  summarise(
    actual_avg_price = mean(Price), 
    deep_predicted_avg = mean(deep_predicted),
    overfitted_predicted_avg = mean(overfitted_predicted),
    count = n(),
    .groups = "drop"
  ) %>%
  filter(count > 20) %>%
  arrange(desc(actual_avg_price)) %>%
  head(15)

# Create combined visualization
combined_pricing_analysis %>%
  select(Airline, airport_code_arrival, actual_avg_price, 
         deep_predicted_avg, overfitted_predicted_avg) %>%
  pivot_longer(cols = c(actual_avg_price, deep_predicted_avg, overfitted_predicted_avg), 
               names_to = "price_type", values_to = "price") %>%
  mutate(
    airline_route = paste(Airline, airport_code_arrival, sep = "-"),
    price_type = case_when(
      price_type == "actual_avg_price" ~ "Actual",
      price_type == "deep_predicted_avg" ~ "Deep Model",
      price_type == "overfitted_predicted_avg" ~ "Overfitted Model"
    ),
    price_type = factor(price_type, levels = c("Actual", "Overfitted Model", "Deep Model"))
  ) %>%
  ggplot(aes(x = reorder(airline_route, price), y = price, fill = price_type)) +
  geom_col(position = "dodge", alpha = 0.7) +
  coord_flip() +
  scale_fill_manual(values = c("Actual" = "steelblue", 
                               "Deep Model" = "darkgreen", 
                               "Overfitted Model" = "darkred")) +
  labs(title = "Airline-Route Pricing: Actual vs Model Predictions",
       subtitle = "Top 15 routes by actual average price",
       x = "Airline-Destination", 
       y = "Average Price (₹)",
       fill = "Price Type") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.text = element_text(size = 14),
        legend.position = "bottom")+ 
  guides(fill = guide_legend(reverse=T))
```

**Combined Pricing Analysis Insights:**

-   **Route-Level Accuracy**: The overfitted model tracks actual prices more closely across airline-route combinations
-   **Premium Routes**: Jet Airways-COK and similar premium routes show largest prediction challenges for the deep model
-   **Consistency**: Both models capture the general pricing hierarchy correctly
-   **Trade-off Visualization**: The improved accuracy comes at the cost of enormous complexity

# Feature Importance Analysis

```{r feature-importance, message=FALSE, warning=FALSE, fig.width=14, fig.height=10}
# Feature importance for both models
deep_feature_importance <- model_deep$variable.importance
overfitted_feature_importance <- model_overfit$variable.importance

# Create comparison plot
deep_feature_df <- data.frame(
  Feature = names(deep_feature_importance),
  Importance = deep_feature_importance,
  Model = "Deep"
) %>% head(10)

overfitted_feature_df <- data.frame(
  Feature = names(overfitted_feature_importance),
  Importance = overfitted_feature_importance,
  Model = "Overfitted"
) %>% head(10)

combined_features <- rbind(deep_feature_df, overfitted_feature_df) %>%
  mutate(Feature = reorder(Feature, Importance))

ggplot(combined_features, aes(x = Feature, y = Importance, fill = Model)) +
  geom_col(position = "dodge", alpha = 0.7) +
  coord_flip() +
  scale_fill_manual(values = c("Deep" = "darkgreen", "Overfitted" = "darkred")) +
  labs(title = "Feature Importance Comparison: Deep vs Overfitted Models",
       subtitle = "Top 10 features by reduction in node impurity",
       x = "Features", 
       y = "Importance Score") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.text = element_text(size = 14))+ 
  guides(fill = guide_legend(reverse=T))
```

**Feature Importance Hierarchy:**

1.  **Route Structure**: `airport_code_first_stop` dominates both models
2.  **Operational Factors**: Duration and number of stops rank highly
3.  **Brand Effects**: Airline importance varies between models
4.  **Temporal Patterns**: Date/time features provide additional predictive power

Both models identify similar key drivers, suggesting the importance rankings reflect genuine pricing patterns rather than model artifacts.

# Business Implications and Model Selection

## Complexity vs Performance Trade-off

```{r complexity-comparison}
complexity_comparison <- data.frame(
  Model = c("Deep Model", "Overfitted Model"),
  Approximate_Splits = c("10", "1,387+"),
  Test_R_squared = c("71.1%", "78.4%"),
  CV_R_squared = c("72.3%", "76.8%"),
  Interpretability = c("High", "None"),
  Deployment_Complexity = c("Low", "Very High"),
  Maintenance_Effort = c("Low", "Very High")
)

complexity_comparison %>%
  kbl(caption = "Model Complexity vs Performance Analysis",
      col.names = c("Model", "Approx. Splits", "Test R²", "Stratified CV R²", 
                   "Interpretability", "Deployment", "Maintenance")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE, position = "left")
```

## Final Model Recommendation: Deep Decision Tree

**Rationale for Deep Model Selection:**

1.  **Balanced Performance**: Achieves 72.3% R² with realistic cross-validation
2.  **Interpretability**: 10 splits create understandable business rules
3.  **Stability**: Lower variance across folds indicates better generalization
4.  **Practical Deployment**: Manageable complexity for production systems
5.  **Business Communication**: Tree structure enables stakeholder explanation

**The Overfitting Trade-off Assessment:**

-   **Improvement**: Only 4.5 percentage points better R² (76.8% vs 72.3%)

-   **Cost**: 130x more complexity (1,387+ vs 10 splits)

-   **Risk**: Higher variance suggests memorization over learning

-   **Conclusion**: The marginal improvement doesn't justify the enormous complexity cost

# Key Business Insights

## Pricing Hierarchy Discovered

1.  **Route Structure Dominates**: Connection patterns (first stop) drive primary pricing decisions
2.  **Operational Costs Matter**: Flight duration and number of stops are key factors
3.  **Brand Positioning**: Airlines differentiate within route-duration constraints
4.  **Dynamic Pricing**: Temporal factors indicate sophisticated revenue management
5.  **Market Segmentation**: Clear pricing tiers exist across airline-route combinations

## Actionable Recommendations

**For Revenue Optimization:** - Focus on route complexity and duration as primary pricing levers - Use airline branding for differentiation within operational constraints - Leverage temporal patterns for dynamic pricing strategies

**For Competitive Strategy:** - Operational efficiency (direct routes, shorter flights) creates competitive advantages - Route structure matters more than brand positioning alone - Premium routes command consistent price premiums across all airlines

**For Model Deployment:** - The deep decision tree provides the optimal balance of accuracy and interpretability - Stratified validation is crucial when dealing with price outliers - Regular model updates should focus on route and temporal pattern changes

# Limitations and Future Work

## Current Limitations

1.  **Discrete Predictions**: Decision trees produce limited prediction granularity
2.  **Outlier Sensitivity**: High-price flights remain challenging to predict accurately
3.  **Temporal Patterns**: Limited seasonal and demand modeling
4.  **Feature Interactions**: Single trees may miss complex multi-way interactions

## Recommendations for Enhancement

1.  **Random Forest**: Combine multiple trees to address prediction granularity and improve generalization
2.  **Advanced Feature Engineering**:
    -   Route complexity metrics (distance, hub importance)
    -   Seasonal demand indicators
    -   Competitor pricing proxies
3.  **Ensemble Methods**: Combine decision trees with linear models for hybrid approach
4.  **Validation Strategy**: Implement time-based splits for more realistic deployment simulation

# Conclusion

This analysis demonstrates that decision trees effectively model flight pricing with meaningful business insights. The deep decision tree achieves strong predictive performance (R² = 72.3%) while maintaining interpretability - a crucial advantage for stakeholder communication and business strategy development.

**Key Findings:**

-   Operational factors (route structure, duration) dominate pricing over brand effects

-   Clear market segmentation exists across airline-route combinations

-   Complexity vs performance trade-offs strongly favor the interpretable deep model

-   Stratified cross-validation is essential for realistic performance assessment with outlier-prone data

**Strategic Implications:** The model reveals that airlines should prioritize operational efficiency and route optimization over pure brand differentiation. The interpretable nature of decision trees makes them valuable for revenue management teams who need to understand and explain pricing decisions to stakeholders.

**Future Development:** While the deep decision tree provides an excellent foundation, ensemble methods (Random Forest) would likely improve prediction accuracy while preserving much of the interpretability advantage. The current model serves as an strong baseline for more sophisticated approaches.

*Analysis completed using R version 4.5.1 with the rpart package for decision tree modeling and stratified cross-validation for robust performance evaluation.*
